[2024-03-02T16:51:37.120+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Batching_Data.Scrapping scheduled__2024-03-02T00:10:00+00:00 [queued]>
[2024-03-02T16:51:37.131+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Batching_Data.Scrapping scheduled__2024-03-02T00:10:00+00:00 [queued]>
[2024-03-02T16:51:37.132+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2024-03-02T16:51:37.132+0000] {taskinstance.py:1363} INFO - Starting attempt 8 of 12
[2024-03-02T16:51:37.133+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2024-03-02T16:51:37.148+0000] {taskinstance.py:1383} INFO - Executing <Task(PythonOperator): Scrapping> on 2024-03-02 00:10:00+00:00
[2024-03-02T16:51:37.158+0000] {standard_task_runner.py:55} INFO - Started process 526 to run task
[2024-03-02T16:51:37.161+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Batching_Data', 'Scrapping', 'scheduled__2024-03-02T00:10:00+00:00', '--job-id', '275', '--raw', '--subdir', 'DAGS_FOLDER/Batching_Data.py', '--cfg-path', '/tmp/tmpfa29eq8g']
[2024-03-02T16:51:37.162+0000] {standard_task_runner.py:83} INFO - Job 275: Subtask Scrapping
[2024-03-02T16:51:37.231+0000] {task_command.py:376} INFO - Running <TaskInstance: Batching_Data.Scrapping scheduled__2024-03-02T00:10:00+00:00 [running]> on host 76a23c179f72
[2024-03-02T16:51:37.317+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Bob Sebastian
AIRFLOW_CTX_DAG_ID=Batching_Data
AIRFLOW_CTX_TASK_ID=Scrapping
AIRFLOW_CTX_EXECUTION_DATE=2024-03-02T00:10:00+00:00
AIRFLOW_CTX_TRY_NUMBER=8
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-03-02T00:10:00+00:00
[2024-03-02T16:51:45.715+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations
  UserWarning,

[2024-03-02T16:51:46.090+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/Batching_Data.py", line 92, in batching_data
    image_multipart = MultipartEncoder(fields=image_data)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests_toolbelt/multipart/encoder.py", line 125, in __init__
    self._prepare_parts()
  File "/home/airflow/.local/lib/python3.7/site-packages/requests_toolbelt/multipart/encoder.py", line 246, in _prepare_parts
    self.parts = [Part.from_field(f, enc) for f in self._iter_fields()]
  File "/home/airflow/.local/lib/python3.7/site-packages/requests_toolbelt/multipart/encoder.py", line 246, in <listcomp>
    self.parts = [Part.from_field(f, enc) for f in self._iter_fields()]
  File "/home/airflow/.local/lib/python3.7/site-packages/requests_toolbelt/multipart/encoder.py", line 219, in _iter_fields
    for k, v in _fields:
TypeError: cannot unpack non-iterable int object
[2024-03-02T16:51:46.108+0000] {taskinstance.py:1406} INFO - Marking task as UP_FOR_RETRY. dag_id=Batching_Data, task_id=Scrapping, execution_date=20240302T001000, start_date=20240302T165137, end_date=20240302T165146
[2024-03-02T16:51:46.124+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 275 for task Scrapping (cannot unpack non-iterable int object; 526)
[2024-03-02T16:51:46.187+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2024-03-02T16:51:46.211+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
